{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71342313",
   "metadata": {},
   "source": [
    "# 05 - Results Analysis & Visualization\n",
    "\n",
    "This notebook provides tools for analyzing MedJEPA training results and\n",
    "visualizing what the model has learned.\n",
    "\n",
    "**Sections:**\n",
    "1. Training History\n",
    "2. Embedding Space Visualization (t-SNE)\n",
    "3. Attention Maps\n",
    "4. Data Efficiency Curves\n",
    "5. Evaluation Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d595f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, json\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Use non-interactive backend if needed\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from medjepa.utils.visualization import (\n",
    "    plot_training_history,\n",
    "    plot_embedding_space,\n",
    "    plot_attention_map,\n",
    "    plot_data_efficiency,\n",
    "    extract_attention_weights,\n",
    "    plot_evaluation_summary,\n",
    ")\n",
    "from medjepa.utils.device import get_device\n",
    "\n",
    "device = get_device()\n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d3663d",
   "metadata": {},
   "source": [
    "## 1. Training History\n",
    "\n",
    "Load and plot the loss curve from pre-training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0945227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training history\n",
    "history_path = '../checkpoints/training_history.json'\n",
    "if os.path.exists(history_path):\n",
    "    with open(history_path) as f:\n",
    "        history = json.load(f)\n",
    "    print(f\"Epochs: {len(history['epochs'])}\")\n",
    "    print(f\"Final loss: {history['train_loss'][-1]:.6f}\")\n",
    "    plot_training_history(history, save_path='../results/training_history.png')\n",
    "else:\n",
    "    print(f'No training history found at {history_path}')\n",
    "    print('Run pre-training first: python scripts/pretrain.py ...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088a0889",
   "metadata": {},
   "source": [
    "## 2. Embedding Space (t-SNE)\n",
    "\n",
    "Visualize how the model organises different disease types in its\n",
    "embedding space. Good representations should cluster similar\n",
    "diseases together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f482ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from medjepa.models.lejepa import LeJEPA\n",
    "from medjepa.evaluation.linear_probe import LinearProbeEvaluator\n",
    "from medjepa.data.datasets import MedicalImageDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# --- Configure these paths ---\n",
    "CHECKPOINT = '../checkpoints/best_model.pt'\n",
    "DATA_DIR   = '../data/raw/ham10000'\n",
    "CSV_PATH   = '../data/raw/ham10000/HAM10000_metadata.csv'\n",
    "LABEL_COL  = 'dx'\n",
    "# ---\n",
    "\n",
    "# Load checkpoint\n",
    "if os.path.exists(CHECKPOINT):\n",
    "    ckpt = torch.load(CHECKPOINT, map_location='cpu', weights_only=False)\n",
    "    cfg  = ckpt.get('config', {})\n",
    "\n",
    "    embed_dim  = cfg.get('embed_dim', 768)\n",
    "    enc_depth  = cfg.get('encoder_depth', 12)\n",
    "    pred_depth = cfg.get('predictor_depth', 6)\n",
    "    image_size = cfg.get('image_size', 224)\n",
    "    patch_size = cfg.get('patch_size', 16)\n",
    "\n",
    "    print(f'Model: embed_dim={embed_dim}, encoder_depth={enc_depth}, '\n",
    "          f'predictor_depth={pred_depth}')\n",
    "else:\n",
    "    print(f'No checkpoint found at {CHECKPOINT}')\n",
    "    print('Run pre-training first: python scripts/run_gpu_full.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5584ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model and load weights\n",
    "if os.path.exists(CHECKPOINT):\n",
    "    model = LeJEPA(\n",
    "        image_size=image_size, patch_size=patch_size,\n",
    "        embed_dim=embed_dim, encoder_depth=enc_depth,\n",
    "        predictor_depth=pred_depth,\n",
    "    )\n",
    "    model.load_state_dict(ckpt['model_state_dict'])\n",
    "    model = model.to(device).eval()\n",
    "    print('Model loaded.')\n",
    "else:\n",
    "    model = None\n",
    "    print('Skipping — no checkpoint.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e99d5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset for t-SNE visualization\n",
    "if model is not None and os.path.exists(DATA_DIR):\n",
    "    dataset = MedicalImageDataset(\n",
    "        image_dir=DATA_DIR, metadata_csv=CSV_PATH,\n",
    "        label_column=LABEL_COL, target_size=(image_size, image_size),\n",
    "    )\n",
    "    loader = DataLoader(dataset, batch_size=64, shuffle=False, num_workers=0)\n",
    "\n",
    "    num_classes = len(set(dataset.labels))\n",
    "    class_names = None\n",
    "    if hasattr(dataset, 'label_map'):\n",
    "        inv_map = {v: k for k, v in dataset.label_map.items()}\n",
    "        class_names = [inv_map[i] for i in range(num_classes)]\n",
    "\n",
    "    print(f'Dataset: {len(dataset)} images, {num_classes} classes')\n",
    "    if class_names:\n",
    "        print(f'Classes: {class_names}')\n",
    "else:\n",
    "    dataset = None\n",
    "    print('Skipping dataset load — no model or data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc831abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract embeddings and plot t-SNE\n",
    "if model is not None and dataset is not None:\n",
    "    evaluator = LinearProbeEvaluator(model, num_classes=num_classes, embed_dim=embed_dim)\n",
    "    features, labels = evaluator.extract_features(loader)\n",
    "    print(f'Extracted: features {features.shape}, labels {labels.shape}')\n",
    "\n",
    "    os.makedirs('../results', exist_ok=True)\n",
    "    plot_embedding_space(\n",
    "        features.numpy(), labels.numpy(), class_names=class_names,\n",
    "        title=f'MedJEPA Embedding Space ({len(dataset)} images)',\n",
    "        save_path='../results/embedding_tsne.png',\n",
    "    )\n",
    "else:\n",
    "    print('Skipping t-SNE — no model/dataset.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daded73c",
   "metadata": {},
   "source": [
    "## 3. Attention Maps\n",
    "\n",
    "Visualize where the model focuses its attention. Clinicians can use\n",
    "this to verify the model looks at the right areas (lesion, not background)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8207d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model is not None and dataset is not None:\n",
    "    from PIL import Image\n",
    "    try:\n",
    "        import cv2\n",
    "    except ImportError:\n",
    "        cv2 = None\n",
    "        print(\"Install opencv-python for attention maps: pip install opencv-python\")\n",
    "\n",
    "    if cv2 is not None:\n",
    "        sample_indices = [0, 100, 500, 1000]\n",
    "        for idx in sample_indices:\n",
    "            if idx >= len(dataset):\n",
    "                continue\n",
    "            img_tensor, label = dataset[idx]\n",
    "\n",
    "            attn_map = extract_attention_weights(model, img_tensor)\n",
    "            attn_resized = cv2.resize(\n",
    "                attn_map, (image_size, image_size),\n",
    "                interpolation=cv2.INTER_LINEAR,\n",
    "            )\n",
    "\n",
    "            img_np = img_tensor.permute(1, 2, 0).numpy()\n",
    "            img_np = (img_np - img_np.min()) / (img_np.max() - img_np.min() + 1e-8)\n",
    "\n",
    "            label_name = class_names[label] if class_names else f'Class {label}'\n",
    "            plot_attention_map(\n",
    "                img_np, attn_resized,\n",
    "                title=f'Sample {idx} — {label_name}',\n",
    "                save_path=f'../results/attention_sample_{idx}.png',\n",
    "            )\n",
    "else:\n",
    "    print('Skipping attention maps — no model/dataset.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018a636a",
   "metadata": {},
   "source": [
    "## 4. Data Efficiency Curves (All Datasets)\n",
    "\n",
    "The \"money plot\" — how accuracy scales with labeled data.\n",
    "This proves MedJEPA's value: strong performance even with very few labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ddf563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load evaluation results (generated by run_gpu_full.py Phase 3)\n",
    "eval_path = '../results/evaluation_results.json'\n",
    "if os.path.exists(eval_path):\n",
    "    with open(eval_path) as f:\n",
    "        eval_results = json.load(f)\n",
    "    print(f\"Loaded results for {len(eval_results)} datasets:\")\n",
    "    for name in eval_results:\n",
    "        print(f\"  - {name}\")\n",
    "else:\n",
    "    print(f'No evaluation results at {eval_path}')\n",
    "    print('Run: python scripts/run_gpu_full.py')\n",
    "    eval_results = {}\n",
    "\n",
    "# --- Multi-Dataset Linear Probe Comparison (bar chart) ---\n",
    "if eval_results:\n",
    "    datasets_with_lp = {k: v for k, v in eval_results.items() if 'linear_probing' in v}\n",
    "\n",
    "    if datasets_with_lp:\n",
    "        names = list(datasets_with_lp.keys())\n",
    "        medjepa_accs = [v['linear_probing']['accuracy'] for v in datasets_with_lp.values()]\n",
    "\n",
    "        # Supervised baseline (if available)\n",
    "        baseline_accs = []\n",
    "        has_baseline = all('supervised_baseline' in v for v in datasets_with_lp.values())\n",
    "        if has_baseline:\n",
    "            baseline_accs = [v['supervised_baseline']['accuracy'] for v in datasets_with_lp.values()]\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(14, 6))\n",
    "        x = np.arange(len(names))\n",
    "        width = 0.35\n",
    "\n",
    "        bars1 = ax.bar(x - width/2 if has_baseline else x, medjepa_accs, width,\n",
    "                       label='MedJEPA (pre-trained)', color='steelblue')\n",
    "        if has_baseline:\n",
    "            bars2 = ax.bar(x + width/2, baseline_accs, width,\n",
    "                           label='Random Init (baseline)', color='lightcoral')\n",
    "\n",
    "        ax.set_ylabel('Accuracy')\n",
    "        ax.set_title('Linear Probe Accuracy: MedJEPA vs Supervised Baseline')\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(names, rotation=30, ha='right')\n",
    "        ax.legend()\n",
    "        ax.set_ylim(0, 1)\n",
    "        ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "        # Add value labels on bars\n",
    "        for bar in bars1:\n",
    "            h = bar.get_height()\n",
    "            ax.annotate(f'{h:.3f}', xy=(bar.get_x() + bar.get_width()/2, h),\n",
    "                       xytext=(0, 3), textcoords='offset points', ha='center', fontsize=8)\n",
    "        if has_baseline:\n",
    "            for bar in bars2:\n",
    "                h = bar.get_height()\n",
    "                ax.annotate(f'{h:.3f}', xy=(bar.get_x() + bar.get_width()/2, h),\n",
    "                           xytext=(0, 3), textcoords='offset points', ha='center', fontsize=8)\n",
    "\n",
    "        os.makedirs('../results', exist_ok=True)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('../results/multi_dataset_linear_probe.png', dpi=150, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"No linear probing results found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc62bbe",
   "metadata": {},
   "source": [
    "## 5. N-Shot Results + Dice Scores\n",
    "\n",
    "Evaluate 5-shot, 10-shot, 20-shot classification and Dice segmentation scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f910f10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- N-Shot Classification Results ---\n",
    "if eval_results:\n",
    "    n_shot_datasets = {k: v for k, v in eval_results.items() if 'n_shot' in v}\n",
    "\n",
    "    if n_shot_datasets:\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        x = np.arange(len(n_shot_datasets))\n",
    "        width = 0.25\n",
    "\n",
    "        shot_keys = ['5-shot', '10-shot', '20-shot']\n",
    "        colors = ['#2ecc71', '#3498db', '#9b59b6']\n",
    "\n",
    "        for i, shot in enumerate(shot_keys):\n",
    "            accs = []\n",
    "            for name, res in n_shot_datasets.items():\n",
    "                accs.append(res['n_shot'].get(shot, {}).get('accuracy', 0))\n",
    "            ax.bar(x + i*width, accs, width, label=shot, color=colors[i])\n",
    "\n",
    "        ax.set_ylabel('Accuracy')\n",
    "        ax.set_title('N-Shot Classification Across Datasets')\n",
    "        ax.set_xticks(x + width)\n",
    "        ax.set_xticklabels(n_shot_datasets.keys(), rotation=30, ha='right')\n",
    "        ax.legend()\n",
    "        ax.set_ylim(0, 1)\n",
    "        ax.grid(axis='y', alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('../results/n_shot_results.png', dpi=150, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"No n-shot results found.\")\n",
    "\n",
    "# --- Dice Segmentation Scores ---\n",
    "if eval_results:\n",
    "    seg_datasets = {k: v for k, v in eval_results.items() if v.get('type') == 'segmentation'}\n",
    "\n",
    "    if seg_datasets:\n",
    "        fig, ax = plt.subplots(figsize=(10, 5))\n",
    "        names = list(seg_datasets.keys())\n",
    "        dice_scores = [v['mean_dice'] for v in seg_datasets.values()]\n",
    "\n",
    "        bars = ax.bar(names, dice_scores, color='teal')\n",
    "        ax.set_ylabel('Mean Dice Score')\n",
    "        ax.set_title('Segmentation Performance (Dice Score)')\n",
    "        ax.set_ylim(0, 1)\n",
    "        ax.axhline(y=0.5, color='red', linestyle='--', alpha=0.5, label='Baseline (0.5)')\n",
    "        ax.legend()\n",
    "        ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "        for bar in bars:\n",
    "            h = bar.get_height()\n",
    "            ax.annotate(f'{h:.3f}', xy=(bar.get_x() + bar.get_width()/2, h),\n",
    "                       xytext=(0, 3), textcoords='offset points', ha='center', fontsize=10)\n",
    "\n",
    "        plt.xticks(rotation=30, ha='right')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('../results/dice_scores.png', dpi=150, bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "        # Per-class Dice\n",
    "        for name, res in seg_datasets.items():\n",
    "            print(f\"\\n{name}:\")\n",
    "            print(f\"  Mean Dice: {res['mean_dice']:.4f}\")\n",
    "            for cls, d in res.get('per_class_dice', {}).items():\n",
    "                label = 'Background' if str(cls) == '0' else 'Foreground'\n",
    "                print(f\"  Class {cls} ({label}): {d:.4f}\")\n",
    "    else:\n",
    "        print(\"No segmentation results found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd18623",
   "metadata": {},
   "source": [
    "## 6. Full Results Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cf0c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Comprehensive Results Table ---\n",
    "import pandas as pd\n",
    "\n",
    "if eval_results:\n",
    "    rows = []\n",
    "    for name, res in eval_results.items():\n",
    "        row = {'Dataset': name, 'Type': res.get('type', '')}\n",
    "\n",
    "        # Linear probe\n",
    "        lp = res.get('linear_probing', {})\n",
    "        row['LP Accuracy'] = f\"{lp['accuracy']:.4f}\" if 'accuracy' in lp else 'N/A'\n",
    "        row['LP AUC'] = f\"{lp['auc']:.4f}\" if lp.get('auc') else 'N/A'\n",
    "\n",
    "        # Baseline\n",
    "        bl = res.get('supervised_baseline', {})\n",
    "        row['Baseline Acc'] = f\"{bl['accuracy']:.4f}\" if 'accuracy' in bl else 'N/A'\n",
    "\n",
    "        # Improvement\n",
    "        if 'accuracy' in lp and 'accuracy' in bl:\n",
    "            imp = lp['accuracy'] - bl['accuracy']\n",
    "            row['Improvement'] = f\"{imp:+.4f}\"\n",
    "        else:\n",
    "            row['Improvement'] = 'N/A'\n",
    "\n",
    "        # N-shot\n",
    "        ns = res.get('n_shot', {})\n",
    "        row['5-shot'] = f\"{ns['5-shot']['accuracy']:.4f}\" if '5-shot' in ns else 'N/A'\n",
    "        row['10-shot'] = f\"{ns['10-shot']['accuracy']:.4f}\" if '10-shot' in ns else 'N/A'\n",
    "\n",
    "        # Dice\n",
    "        row['Dice'] = f\"{res['mean_dice']:.4f}\" if 'mean_dice' in res else 'N/A'\n",
    "\n",
    "        rows.append(row)\n",
    "\n",
    "    results_df = pd.DataFrame(rows)\n",
    "    print(\"=\" * 100)\n",
    "    print(\"MEDJEPA FULL EVALUATION RESULTS\")\n",
    "    print(\"=\" * 100)\n",
    "    print(results_df.to_string(index=False))\n",
    "    print(\"=\" * 100)\n",
    "\n",
    "    # Save as CSV for the submission\n",
    "    os.makedirs('../results', exist_ok=True)\n",
    "    results_df.to_csv('../results/full_results_table.csv', index=False)\n",
    "    print(\"\\nSaved to results/full_results_table.csv\")\n",
    "else:\n",
    "    print(\"No results to summarize. Run: python scripts/run_gpu_full.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379028fa",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**All plots are saved to `results/` folder.**\n",
    "\n",
    "### Generated Artifacts:\n",
    "- `results/training_history.png` — Loss curve\n",
    "- `results/embedding_tsne.png` — t-SNE embedding space\n",
    "- `results/attention_sample_*.png` — Attention maps\n",
    "- `results/multi_dataset_linear_probe.png` — MedJEPA vs baseline (all datasets)\n",
    "- `results/n_shot_results.png` — 5/10/20-shot classification\n",
    "- `results/dice_scores.png` — Segmentation Dice scores\n",
    "- `results/full_results_table.csv` — Complete results table\n",
    "\n",
    "### To reproduce full results:\n",
    "```bash\n",
    "python scripts/run_gpu_full.py\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
